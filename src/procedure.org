#+TITLE: AI-Assisted Software Development Procedure for Data Science
#+AUTHOR: [Your Name]
#+DATE: [Current Date]
#+VERSION: 1.0
#+TARGET_SCOPE: Simple to intermediate data science tools (2-7 days development time)
#+OUTPUT: Research-grade, reproducible tools with comprehensive testing and documentation

* Living Document Update Prompt
#+BEGIN_COMMENT
PURPOSE: FOR LLM ASSISTANCE WITH PROCEDURE REFINEMENTS
#+END_COMMENT

#+BEGIN_SRC text
This is a living document containing a systematic procedure for AI-assisted software development in data science. I've been testing this procedure on real projects and need to update it based on practical experience.

CURRENT DOCUMENT:
[Paste the complete procedure document]

MY TESTING EXPERIENCE:
[Describe what worked well, what didn't work, specific problems encountered, timing issues, workflow bottlenecks, etc.]

SPECIFIC AREAS FOR IMPROVEMENT:
[List particular sections, phases, or techniques that need refinement]

Please help me refine this procedure by:
1. Identifying which parts of my experience suggest systematic improvements vs. one-off issues
2. Proposing specific modifications to address the problems I encountered
3. Suggesting additional guidance or clarifications for areas that were unclear in practice
4. Maintaining the overall structure and philosophy while improving practical effectiveness
5. Updating the version number (current: X.X â†’ next: X.Y) 

Focus on making the procedure more robust and executable based on real-world usage while preserving the systematic approach and learning objectives.

Ask me clarifying questions about my experience if needed to provide the most helpful refinements.
#+END_SRC

** Update Protocol
- Test the procedure on real projects
- Document what works and what needs improvement
- Use the prompt above to get systematic refinements
- Increment version number for each refinement cycle
- Maintain the core philosophy: systematic design thinking + learning-focused implementation + research-grade quality

* Overview

This procedure systematically develops focused, project-specific data analysis tools while maintaining research-grade quality standards. The workflow emphasizes thorough upfront planning to minimize debugging time and maximize learning value through granular, testable code units.

* Human-LLM Interaction Framework

** Clear handoff specifications for each phase

| Phase | Human Input                     | LLM Input                            | Human Output         | LLM Output                 |
|-------+---------------------------------+--------------------------------------+----------------------+----------------------------|
|   1.1 | Manual drafting                 | None                                 | Intent Document      | None                       |
|   1.2 | Intent Document                 | Intent Document                      | Negative Space Map   | Socratic failure questions |
|   2.1 | Intent + Negative Space + Reuse | Intent + Negative Space + Reuse      | Draft Specifications | Socratic design questions  |
|   2.2 | Draft Specifications            | Optional: specific design challenges | Final Specifications | Optional: design guidance  |
|   3.1 | Final Specs + Code Repos        | Final Specs + Code Repos             | Quality review       | Prompt Guide + Todo List   |
|   4.X | Prompts from Guide              | Individual prompts                   | Working code units   | Code + explanations        |

** Key Principle
Documents created FOR LLMs are structured for machine consumption. Documents created BY LLMs are structured for human use. Documents created by humans FOR humans prioritize clarity and decision-making.

* Phase 1: Project Bootstrap
:PROPERTIES:
:PHASE: 1
:OBJECTIVE: Establish foundation
:END:

** 1.1 Goal Clarification
:PROPERTIES:
:OBJECTIVE: Establish crystal-clear project objectives before any technical decisions
:HUMAN_ACTIVITY: No LLM involvement
:END:

*** HUMAN ACTIVITY (No LLM involvement)

**** 1. Draft Intent Document by hand (pen and paper)
- Problem statement (what manual process are you replacing/optimizing?)
- Success criteria (quantifiable metrics: time savings, statistical power, etc.)
- Input/output specifications (file formats, data structure, expected volumes)
- Key constraints (timeline, computational resources, compatibility requirements)
- Stakeholders and collaboration requirements

#+BEGIN_QUOTE
*Why handwritten*: Handwriting engages deeper cognitive processes essential for establishing the project foundation clearly.
#+END_QUOTE

**** 2. Assess Code Reuse Opportunities (review existing repositories)
- Review previous projects for relevant patterns, functions, or approaches
- Identify specific components that could be reused or adapted
- Document existing solutions to avoid reinventing solved problems
- Note any consistency requirements with existing tools

**** 3. Validate Intent (human collaboration)
- Describing the tool to a colleague and noting their questions
- Writing 3-5 concrete usage examples with realistic data
- Identifying the *MVP core* (Minimum Viable Product: the single most critical feature that makes the tool useful - if you could only implement one feature, what would it be?)
- Confirming which parts are genuinely new vs. adaptations of existing work

**** HUMAN OUTPUT
Intent Document (typed version of handwritten draft, 1-2 pages max) including reuse assessment

**** Benefits of Early Reuse Assessment
- Reduces development time by leveraging proven solutions
- Maintains consistency with existing tools for collaboration
- Focuses new development effort on genuinely novel problems
- Provides more accurate project timeline estimates
- Preserves learning value through adaptation rather than repetition

** 1.2 Negative Space Mapping (Socratic Failure Mode Analysis)
:PROPERTIES:
:OBJECTIVE: Systematically identify catastrophic failure modes before specification writing
:COLLABORATION: Human provides structured input to LLM, LLM provides Socratic questioning, Human creates output document
:END:

*Process*: Engage LLM as Socratic teacher to systematically explore failure modes across four dimensions:

*** 1.2.1 Data Flow Failure Modes

**** HUMAN INPUT TO LLM:
#+BEGIN_SRC text
I'm developing [brief tool description from Intent Document]. 

Here is my complete Intent Document:
[Copy entire Intent Document]

Here are my data transformations: [extract and list each step where data gets modified/filtered/sampled/aggregated from Intent Document].

Act as my Socratic teacher. Ask me probing questions to help me discover how each transformation could break downstream processes. Focus on edge cases where the transformation could produce unexpected output formats, empty datasets, or violated assumptions that later components depend on.

Ask ONE question at a time, building on my responses.
#+END_SRC

**** Workflow
- *LLM OUTPUT*: Series of probing questions
- *HUMAN ACTIVITY*: Answer questions, engage in dialogue
- *HUMAN OUTPUT*: Notes on discovered failure modes

*Continue until you can confidently answer*: "How could each data transformation create impossible requirements for downstream components?"

*** 1.2.2 Assumption Violations

**** HUMAN INPUT TO LLM:
#+BEGIN_SRC text
For my project [description from Intent Document], I'm making these assumptions: [extract all assumptions from Intent Document about data format, user behavior, computational resources, biological phenomena, etc.].

Be my Socratic teacher. Help me discover what happens when each assumption is false. Ask probing questions to uncover hidden assumptions I haven't listed and explore realistic scenarios where my stated assumptions break.

Focus on assumptions that, if violated, would require fundamental design changes rather than minor fixes.
#+END_SRC

**** Workflow
- *LLM OUTPUT*: Series of probing questions about assumptions
- *HUMAN ACTIVITY*: Answer questions, identify additional assumptions
- *HUMAN OUTPUT*: Notes on assumption violations and their consequences

*Continue until*: You've identified assumptions that could cascade into system-wide design changes.

*** 1.2.3 Integration Disasters

**** HUMAN INPUT TO LLM:
#+BEGIN_SRC text
My tool will have these major components: [extract components from Intent Document and list each script/module and its primary responsibility].

Act as my Socratic teacher. Help me discover how component interactions could create impossible requirements. Ask questions about how Component A's edge cases could make Component B's job impossible, or how optimizing for Component X might break Component Y.

Pay special attention to shared data structures and intermediate file formats.
#+END_SRC

**** Workflow
- *LLM OUTPUT*: Questions about component interactions
- *HUMAN ACTIVITY*: Analyze interactions, identify conflict scenarios
- *HUMAN OUTPUT*: Notes on integration failure modes

*Continue until*: You understand how each component's failure modes affect every other component.

*** 1.2.4 Scale-Up Failures

**** HUMAN INPUT TO LLM:
#+BEGIN_SRC text
My tool is designed for [current scope from Intent Document: data size, complexity, etc.] but may need to handle [realistic scale-up scenarios from Intent Document].

Be my Socratic teacher. Ask questions to help me identify what works for simple cases but breaks at realistic scale. Focus on computational complexity, memory usage, user interface complexity, and maintenance overhead.
#+END_SRC

**** Workflow
- *LLM OUTPUT*: Questions about scalability limitations
- *HUMAN ACTIVITY*: Consider scale implications
- *HUMAN OUTPUT*: Notes on scale-up failure modes

*Continue until*: You understand which design decisions are scale-limiting.

**** HUMAN OUTPUT
Negative Space Map document (created by human, consolidating notes from all four dialogues) listing identified failure modes and their potential cascading effects.

* Phase 2: Specification Development
:PROPERTIES:
:PHASE: 2
:OBJECTIVE: Convert goals to technical specifications
:END:

** 2.1 Technical Specification Brainstorming (Socratic Design Dialog)
:PROPERTIES:
:COLLABORATION: Human provides design challenge to LLM, LLM provides Socratic questioning for systematic design exploration
:OBJECTIVE: Systematically work backwards from goals to implementation through structured exploration of design decisions
:END:

*** HUMAN INPUT TO LLM:
#+BEGIN_SRC text
I need to develop technical specifications for my data science tool. I have completed the foundational analysis:

INTENT DOCUMENT:
[Copy complete Intent Document from Phase 1.1]

NEGATIVE SPACE MAP:
[Copy complete Negative Space Map from Phase 1.2 - all identified failure modes and constraints]

REUSE OPPORTUNITIES:
[Copy reuse assessment from Phase 1.1]

Act as my Socratic teacher to help me work backwards from my goals to implementation. I need to systematically explore design decisions, data structures, algorithms, user interfaces, and technical approaches.

Focus on helping me discover:
- What data structures and file formats will support my goals while avoiding the failure modes we identified?
- What algorithmic approaches will handle the edge cases and scale requirements?
- How should components interact to prevent the integration disasters we mapped?
- What user interface and error handling will make the tool robust and usable?

Ask ONE question at a time, building on my responses. Help me think through the implications of each design choice before moving to the next decision.

Start with the highest-level architectural decisions and progressively get more specific.
#+END_SRC

*** Workflow
- *LLM OUTPUT*: Series of design exploration questions
- *HUMAN ACTIVITY*: Answer questions, explore design implications, document design decisions
- *HUMAN OUTPUT*: Draft technical specifications with rationale for each design decision

*Continue until*: You have systematically explored all major design decisions and their implications.

** 2.2 Specification Iteration and Validation
:PROPERTIES:
:ACTIVITY: HUMAN ACTIVITY with optional LLM consultation
:END:

*** Iterative refinement process

**** 1. Deep reflection on draft specifications (human-only)
- Do the specifications address all goals from the Intent Document?
- Are all failure modes from the Negative Space Map mitigated?
- Are the design decisions internally consistent?
- Can you trace a clear path from specifications to working implementation?

**** 2. Optional LLM consultation for specific design challenges
- Complex algorithmic decisions
- Data structure optimization
- Error handling strategies
- Integration approach refinement

**** 3. Specification refinement
- Update specifications based on reflection and consultation
- Add missing details discovered during reflection
- Resolve any internal contradictions
- Ensure complete coverage of identified requirements

*** Decision criteria for moving to Phase 3.1
- You can confidently explain every design decision and its rationale
- All major failure modes from Phase 1.2 are addressed in the specifications
- You can visualize the complete data flow from input to output
- No remaining uncertainty about fundamental architectural choices
- The specifications feel complete enough for systematic decomposition

**** HUMAN OUTPUT
Final validated technical specifications ready for atomic decomposition

#+BEGIN_QUOTE
*Critical Time Allocation Note*: Phases 1.1 through 2.2 should consume approximately *67% of total project time*. This upfront investment in design quality dramatically reduces debugging and rework time in later phases.
#+END_QUOTE

* Phase 3: Atomic Unit Decomposition
:PROPERTIES:
:PHASE: 3
:OBJECTIVE: Convert specifications into atomic, testable units
:END:

** 3.1 Specification Decomposition (Two-Document Approach)
:PROPERTIES:
:OBJECTIVE: Convert technical specifications into atomic, independent, testable units while maintaining learning value
:END:

*** 3.1.1 Generate Decomposition Documents
:PROPERTIES:
:HANDOFF: Human provides structured specifications to LLM, LLM creates implementation documents
:END:

**** HUMAN INPUT TO LLM:
#+BEGIN_SRC text
I have completed technical specifications for a data science tool. I need you to break these specifications into atomic units that build incrementally and can be coded and tested one at a time.

SPECIFICATIONS:
[Copy complete technical specifications from Phase 2.1]

EXISTING CODE REPOSITORIES FOR REUSE:
[Include relevant previous project repositories, particularly highlighting reusable functions, patterns, or approaches identified in Phase 1.1]

Previous Project Examples:
- fly_behavior_analysis: [Include repository link or key code sections]
- [Other relevant projects]

Key reusable components identified:
- [List specific functions, patterns, or modules that could be adapted from Phase 1.1 assessment]

REQUIREMENTS FOR ATOMIC UNITS:
- Each unit should perform a single, clearly defined action
- Unit 1 must be completely standalone and testable in isolation
- Unit 2 can depend on Unit 1 and must be testable with Unit 1 present
- Unit 3 can depend on Units 1-2 and must be testable with Units 1-2 present
- And so on... Unit N can depend on Units 1 through N-1
- Each unit should be understandable to someone learning Python
- Each unit must include specific test requirements that work with all previously completed units available
- When possible, units should adapt/reuse existing code rather than creating from scratch
- Clearly indicate which units involve code reuse vs. new development

EXAMPLE INCREMENTAL BUILDING:
If creating a data processing pipeline:
- Unit 1: "Adapt load_csv_file() from fly_behavior_analysis for new data format" (reuse with modifications)
- Unit 2: "Create new data cleaning function using validation patterns from Unit 1" (new code building on adapted foundation)
- Unit 3: "Generate summary statistics using cleaned data from Unit 2" (can use Units 1-2)
- Unit 4: "Adapt visualization approach from previous project for new statistics" (reuse with modifications)

Each unit builds on the solid, tested foundation of previous units and leverages existing proven solutions where appropriate.

OUTPUT TWO DOCUMENTS:

DOCUMENT 1: PROMPT ENGINEERING GUIDE (FOR SUBSEQUENT LLM INTERACTIONS)
For each identified unit, provide:
- Unit ID and clear descriptive name
- Whether this unit involves: NEW CODE, CODE ADAPTATION, or DIRECT REUSE
- For adaptations/reuse: specific reference to existing code location
- Precise coding prompt that includes:
  * Exact function signature
  * Input/output specifications
  * Required error handling
  * Specific unit test requirements
  * Code documentation standards
  * For reuse: specific modifications needed from original
- Dependencies on previous units
- Expected completion time

DOCUMENT 2: PERSONAL TODO LIST (FOR HUMAN PROJECT MANAGEMENT)
A milestone-based checklist containing:
- Sequential list of all units in dependency order
- Estimated time for each unit (accounting for reuse vs. new development)
- Code reuse milestones (when to integrate adapted components)
- Key integration points where multiple units come together
- Testing milestones (when to run integration tests)
- Documentation checkpoints

Be systematic and thorough. Prioritize code reuse where appropriate to accelerate development while maintaining learning objectives.
#+END_SRC

**** LLM OUTPUT
- *Document 1*: Prompt Engineering Guide (structured for LLM consumption)
- *Document 2*: Personal Todo List (structured for human project management)

*** 3.2 Decomposition Quality Control
:PROPERTIES:
:ACTIVITY: HUMAN ACTIVITY (No LLM involvement)
:END:

**** Review criteria
- Is Unit 1 completely standalone with no dependencies?
- Can each subsequent unit be coded using only previously completed units (Unit N depends only on Units 1 through N-1)?
- Does each unit have clear, testable success criteria that work with the incremental codebase?
- Are dependencies between units explicitly documented in dependency order?
- Do the prompts include sufficient context for quality code generation with existing foundation?
- Is the granularity appropriate for learning Python concepts while building incrementally?

*If quality issues found*: Iterate with LLM to refine decomposition.

**** HUMAN OUTPUT
Validated Prompt Engineering Guide and Personal Todo List ready for development

* Phase 4: Systematic Code Development
:PROPERTIES:
:PHASE: 4
:OBJECTIVE: Implement atomic units systematically
:END:

** 4.1 Repository Setup
:PROPERTIES:
:TIMING: Before coding first unit
:END:

*** Setup Tasks
1. Initialize git repository with clear README
2. Set up project structure (following your proven approach)
3. Create environment.yml and requirements.txt
4. Establish testing framework (pytest)
5. Create initial documentation structure

** 4.2 Per-Unit Development Workflow
:PROPERTIES:
:SCOPE: For each unit in the Prompt Engineering Guide
:END:

*** Step 1: Prompt Execution
:PROPERTIES:
:HANDOFF: Human takes prompt from Guide, gives to LLM, receives code
:END:

**** HUMAN INPUT TO LLM:
- Copy exact prompt from Prompt Engineering Guide for current unit
- For CODE ADAPTATION units: include existing code reference in prompt
- For DIRECT REUSE units: copy existing code and modify as specified
- For NEW CODE units: use standard LLM generation

**** Workflow
- *LLM OUTPUT*: Generated/adapted code with tests
- *HUMAN ACTIVITY*: Request modifications if output doesn't match prompt specifications

*** Step 2: Code Understanding (Learning Phase)
:PROPERTIES:
:COLLABORATION: Human learns by questioning LLM about generated code
:END:

**** For NEW CODE or significant adaptations

***** HUMAN INPUT TO LLM:
#+BEGIN_SRC text
I received this code for [unit description]:

[Paste generated/adapted code]

I'm learning Python and need to understand every part. Please explain:
1. Each function and its purpose
2. Any Python concepts or libraries I might not know
3. Why this approach was chosen (especially vs. the original if adapted)
4. How the error handling works
5. What each part of the test does

Ask me questions to check my understanding. Don't move on until I can explain the code back to you.
#+END_SRC

***** Workflow
- *LLM OUTPUT*: Explanations and comprehension questions
- *HUMAN ACTIVITY*: Answer questions, ask for clarification

**** For DIRECT REUSE
Review existing code documentation and tests to ensure understanding.

*Continue until*: You can explain the code confidently without reference.

*** Step 3: Integration
:PROPERTIES:
:ACTIVITY: HUMAN ACTIVITY (No LLM involvement)
:END:

- Add code to project repository
- Update imports and dependencies
- Ensure code follows project standards
- Update documentation

*** Step 4: Testing
:PROPERTIES:
:ACTIVITY: HUMAN ACTIVITY (No LLM involvement)
:END:

- Run unit tests for current unit (with all previously completed units available)
- Run integration tests with all previously completed units
- Verify new unit works correctly with existing foundation
- If tests fail: troubleshoot systematically, document issues

*** Step 5: Optional Troubleshooting
:PROPERTIES:
:COLLABORATION: HUMAN-LLM COLLABORATION (if needed)
:END:

- *HUMAN INPUT TO LLM*: Error messages, failing test descriptions
- *LLM OUTPUT*: Debugging assistance and suggestions
- *HUMAN ACTIVITY*: Apply fixes, test edge cases manually, refine error handling

*** Step 6: Version Control
:PROPERTIES:
:ACTIVITY: HUMAN ACTIVITY (No LLM involvement)
:END:

- Commit with descriptive message
- Tag major milestones
- Update changelog

*** Step 7: Documentation
:PROPERTIES:
:ACTIVITY: HUMAN ACTIVITY (No LLM involvement)
:END:

- Update README with new functionality
- Document any deviations from original specifications
- Note lessons learned for future reference

*** Step 8: Progress Tracking
:PROPERTIES:
:ACTIVITY: HUMAN ACTIVITY (No LLM involvement)
:END:

- Check off unit in Personal Todo List
- Estimate remaining time
- Proceed to next unit

** 4.3 Integration Milestones
:PROPERTIES:
:TIMING: At designated integration points
:END:

*** Milestone Tasks
1. Run full test suite
2. Test end-to-end workflows with realistic data
3. Validate outputs match specifications
4. Document any discovered limitations
5. Update project documentation

* Phase 5: Quality Assurance and Finalization
:PROPERTIES:
:PHASE: 5
:OBJECTIVE: Ensure research-grade quality
:END:

** 5.1 Final Integration Testing
- Test complete pipeline with real project data
- Validate all outputs match specification requirements
- Perform edge case testing based on negative space map
- Document any remaining limitations

** 5.2 Documentation Finalization
- Complete README with installation and usage instructions
- Document all known limitations and workarounds
- Include examples with realistic data
- Add references to theoretical background

** 5.3 Repository Quality Standards
:PROPERTIES:
:STANDARD: Ensure repository meets research-grade standards
:END:

*** Quality Checklist
- [ ] Comprehensive README
- [ ] All dependencies documented
- [ ] Complete test coverage
- [ ] Clear licensing
- [ ] Reproducible examples
- [ ] Version tagging

* Workflow Timing Guidelines

** Phase Distribution
- *Phase 1 (Bootstrap)*: 1-2 days (~25% of project time)
  - Goal clarification: 3-6 hours
  - Negative space mapping: 6-10 hours

- *Phase 2 (Specifications)*: 1.5-3 days (~40% of project time)
  - Specification brainstorming: 6-12 hours
  - Specification iteration: 6-12 hours

#+BEGIN_QUOTE
*Critical Design Investment*: Phases 1-2 should consume *~67% of total project time* to ensure robust design foundation
#+END_QUOTE

- *Phase 3 (Decomposition)*: 0.5-1 day (~15% of project time)
  - Atomic unit decomposition: 3-6 hours
  - Quality control: 1-2 hours

- *Phase 4 (Development)*: 1-1.5 days (~15% of project time)
  - Per-unit development: 10-20 minutes per unit
  - Integration milestones: 30-60 minutes each

- *Phase 5 (Finalization)*: 0.25-0.5 day (~5% of project time)
  - Final testing and documentation: 2-4 hours

** Total Range
4.5-7.5 days

** Key Insight
Heavy upfront design investment (67% of time) dramatically reduces debugging and rework time, making total development time shorter and more predictable.

* Success Criteria

A successful project completion includes:
- [X] All units pass individual tests
- [X] Complete pipeline processes realistic data successfully
- [X] Code is readable and well-documented
- [X] Repository follows research-grade standards
- [X] No blocking errors in normal usage scenarios
- [X] Author can explain every code component confidently
- [X] Statistical outputs meet original specifications
- [X] Tool addresses original problem statement

* Adaptation Guidelines

** For simpler projects
- Compress bootstrap phase (focus on data flow failures)
- Reduce decomposition granularity
- Streamline documentation requirements

** For more complex projects
- Extend negative space mapping with additional failure scenarios
- Add intermediate integration milestones
- Consider prototype development before full specifications
- Include performance testing at integration points

** Learning focus adjustments
- Increase unit granularity for unfamiliar concepts
- Add explicit concept-learning checkpoints
- Include additional explanation prompts for complex algorithms

#+BEGIN_QUOTE
This procedure provides a systematic, scalable approach to developing research-grade data science tools while maintaining learning objectives and minimizing debugging overhead through comprehensive upfront planning.
#+END_QUOTE

* Complete Human-LLM Workflow Summary

| Phase | Step                | Human Input                     | Human Activity                              | LLM Input                            | LLM Output                   | Human Output              |
|-------+---------------------+---------------------------------+---------------------------------------------+--------------------------------------+------------------------------+---------------------------|
|   1.1 | Goal Clarification  | Pen & paper                     | Handwrite, validate with colleague          | None                                 | None                         | Intent Document           |
|   1.2 | Negative Space      | Intent Document                 | Answer questions, take notes                | Intent Document + context            | Socratic questions           | Failure mode notes        |
|   1.2 | Final Consolidation | All failure notes               | Create consolidated document                | None                                 | None                         | Negative Space Map        |
|   2.1 | Spec Brainstorming  | Intent + Negative Space + Reuse | Answer design questions, document decisions | Intent + Negative Space + Reuse      | Design exploration questions | Draft specifications      |
|   2.2 | Spec Iteration      | Draft specifications            | Deep reflection, optional LLM consultation  | Optional: specific design challenges | Optional: design guidance    | Final specifications      |
|   3.1 | Decomposition       | Final Specs + Code Repos        | Structure input, review output              | Specs + repos + requirements         | Prompt Guide + Todo List     | Quality-checked documents |
| 4.1-8 | Each Unit           | Prompt from Guide               | Execute 8-step workflow                     | Individual prompts                   | Code + explanations          | Working code units        |
|     5 | Finalization        | All outputs                     | Final testing & documentation               | None (or optional assistance)        | None (or assistance)         | Research-grade repository |

** Key Insight
The procedure alternates between deep human thinking (handwritten foundation, specification writing) and collaborative human-LLM work (Socratic questioning, code generation), ensuring both cognitive rigor and implementation efficiency.
